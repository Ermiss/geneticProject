{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"genetic.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNRxgB+F0BuqF2GKByJvrMT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uX6NlcgUWF90"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","import math\n","import random \n","from random import choices\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","drive.mount('/content/drive')\n","data = open(\"/content/drive/MyDrive/dataset/data/x_train.csv\")\n","x_train = np.loadtxt(data, delimiter=\",\")"]},{"cell_type":"code","source":["# Control variables\n","population_size = 200\n","vocab_size = 8520\n","sen_size = len(x_train)\n","elite_size = 2\n","# new_ones = population_size * 0.1\n","cross_size = population_size - elite_size\n","cross_prob = 0.6\n","mutation_prob = 0\n","generation = 100"],"metadata":{"id":"gOCZcvGlWOV7","executionInfo":{"status":"ok","timestamp":1654743940975,"user_tz":-180,"elapsed":406,"user":{"displayName":"Ερμης Αρβανιτης","userId":"12156976398276473890"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Creating the tf-idf \n","# Counting all the words in the texts\n","sen_len = []\n","counter = 0\n","for i in x_train:\n","  for j in i:\n","    if j != 0:\n","      counter += j\n","  sen_len.append(counter)\n","# Calculate tf\n","tf = []\n","for i in range(sen_size):\n","  temp = [0] * vocab_size  \n","  for j in range(vocab_size):\n","    if x_train[i][j] != 0:\n","      temp[j] = x_train[i][j] / sen_len[i]\n","  tf.append(temp)\n","# Calculate idf\n","idf = []\n","for i in range(vocab_size):\n","  counter = 0\n","  for j in range(sen_size):\n","    if x_train[j][i] != 0:\n","      counter += 1\n","  idf.append(math.log(sen_size / counter))\n","# Calculate the tf-idf\n","tf_idf = []\n","for i in range(vocab_size):\n","  temp = [0] * vocab_size\n","  for j in range(sen_size):\n","    temp[j] = tf[j][i] * idf[i]\n","  tf_idf.append(temp)\n","# Calculate the avg_tf_idf\n","avg = []\n","for i in range(vocab_size):\n","  temp = 0\n","  for j in range(sen_size):\n","    temp = temp + tf_idf[i][j]\n","  avg.append(temp)"],"metadata":{"id":"zlxtmnCYWOQK","executionInfo":{"status":"ok","timestamp":1654743267207,"user_tz":-180,"elapsed":143294,"user":{"displayName":"Ερμης Αρβανιτης","userId":"12156976398276473890"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["final = []\n","# Scaling the fitness function\n","scaler = 10**6\n","for times in range(10):\n","  population = []\n","  solutions = []\n","  # Create the population\n","  for i in range(population_size):\n","    solutions = []\n","    ones = random.randint(0, vocab_size)\n","    temp = [0] * vocab_size \n","    counter = 0\n","    while counter < ones:\n","      index = random.randint(0, vocab_size-1)\n","      if temp[index] == 0:\n","        temp[index] = 1\n","        counter += 1\n","    population.append(temp)\n","    \n","  for gen in range(generation):\n","    # Calculate fitness function \n","    fitness = []\n","    # Stores all the invalid solutions with the number of words that are missing from being valid\n","    problematic = {}\n","    temp = 0\n","    counter = 0\n","    for i in range(population_size):\n","      for j in range(vocab_size):\n","        if population[i][j] == 1:\n","          counter += 1\n","          # First criteria\n","          temp = temp + avg[j]\n","      if counter < 1000:\n","        fitness.append(0)\n","        problematic[i] = 1000 - counter\n","        counter = 0\n","      else:\n","        # Second criteria\n","        temp = temp/(counter**2)\n","        fitness.append(scaler * temp)\n","      temp = 0\n","      counter = 0\n","\n","    solutions.append(np.max(fitness))\n","    \n","    # Elitism for invalid populations or random replacement\n","    for i in range(population_size):\n","      if fitness[i] == 0:\n","        # Repair with adding words\n","        counter = problematic[i] \n","        for j in range(vocab_size):\n","          if counter == 0:\n","            break\n","          if population[i][j] == 0:\n","            population[i][j] = 1\n","            counter -= 1\n","    # Getting the elite\n","    elite = []\n","    temp = fitness.copy()\n","    temp.sort(reverse=True)\n","    for i in range(elite_size):\n","      for j in range(population_size):\n","        if temp[i] == fitness[j]:\n","          elite.append(population[j])\n","          counter = 0\n","          for k in elite[i]:\n","            if k == 1:\n","              counter += 1\n","          break\n","      \n","    # Select the genes for crossover\n","    # Selection with Weighted Roulette\n","    selected = []\n","    temp = fitness.copy()\n","    for i in range(cross_size):\n","      max = sum(fitness)\n","      pick = random.uniform(0, max)\n","      current = 0\n","      for j in range(population_size):\n","        current += temp[j]\n","        if current > pick:\n","          selected.append(j)\n","          break\n","\n","    # Generating new genes from crossover\n","    new_genes = []\n","    # Uniform crossover\n","    for i in range(0, cross_size, 2):\n","      if random.random() < cross_prob:\n","        temp = []\n","        # Creating the form\n","        for j in range(vocab_size):\n","          coin = random.randint(0, 1)\n","          if coin == 1:\n","            temp.append(population[selected[i]][j])\n","          else: \n","            temp.append(population[selected[i+1]][j])\n","        child1 = []\n","        child2 = []\n","        for j in range(vocab_size):\n","          if temp[j] == 1:\n","            child1.append(population[selected[i]][j])\n","            child2.append(population[selected[i+1]][j])\n","          else:\n","            child1.append(population[selected[i+1]][j])\n","            child2.append(population[selected[i]][j])\n","        new_genes.append(child1.copy())\n","        new_genes.append(child2.copy())\n","      else:\n","        new_genes.append(population[selected[i]].copy())\n","        new_genes.append(population[selected[i+1]].copy())\n","\n","    for i in elite:\n","      counter = 0\n","      for j in i:\n","        if j == 1:\n","          counter += 1\n","    # Mutation\n","    for i in range(cross_size):\n","      for j in range(vocab_size):\n","        if random.random() < mutation_prob:\n","          new_genes[i][j] = abs(new_genes[i][j] - 1)\n","\n","    # The genes that pass to the next generation\n","    population = []\n","    for i in elite:\n","      counter = 0\n","      for j in i:\n","        if j == 1:\n","          counter += 1\n","      population.append(i)\n","  \n","    for i in new_genes:\n","      counter = 0\n","      for j in i:\n","        if j == 1:\n","          counter += 1\n","      population.append(i)\n","    \n","  final.append(solutions)\n","  print(\"final \" + str(final))\n","\n","evolution = []\n","\n","for i in range(generation):\n","  temp = 0\n","  for j in range(times + 1):\n","    temp += final[j][i]\n","  temp = temp / (times + 1)\n","  evolution.append(temp)\n","print(\"evolution\")\n","print(evolution)"],"metadata":{"id":"KKK2zHfYWZVt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ploting the evolution of the best solution graph\n","generations = range(1, generation + 1)\n","plt.plot(generations, evolution, 'y', label='Evolution of Best Solution')\n","plt.title('Evolution of Best Solution')\n","plt.xlabel('Generation')\n","plt.ylabel('Fitness Value')\n","plt.savefig(\"evolution.png\")\n","files.download(\"evolution.png\") \n","plt.show()"],"metadata":{"id":"5pfQ202pXJ3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = open(\"/content/drive/MyDrive/dataset/data/x_train.csv\")\n","x_train = np.loadtxt(data, delimiter=\",\")\n","\n","data = open(\"/content/drive/MyDrive/dataset/data/x_test.csv\")\n","x_test = np.loadtxt(data, delimiter=\",\")\n","data = open(\"/content/drive/MyDrive/dataset/data/train-label.dat\")\n","y_train = np.loadtxt(data, delimiter=\" \", dtype='int')\n","\n","data = open(\"/content/drive/MyDrive/dataset/data/test-label.dat\")\n","y_test = np.loadtxt(data, delimiter=\" \", dtype='int')\n","# Downsize the x_train according to the evolutionary algorithm\n","# Count how many words in the elite\n","counter = 0\n","for i in elite[0]:\n","  if i == 1:\n","    counter += 1\n","\n","new_x_train = []\n","for i in range(len(x_train)):\n","  temp = [0] * counter\n","  for j in range(counter):\n","    if elite[0][j] == 1:\n","      temp[j] = x_train[i][j]\n","  new_x_train.append(temp)\n","x_train = new_x_train.copy()\n","\n","new_x_test = []\n","for i in range(len(x_test)):\n","  temp = [0] * counter\n","  for j in range(counter):\n","    if elite[0][j] == 1:\n","      temp[j] = x_test[i][j]\n","  new_x_test.append(temp)\n","x_test = new_x_test.copy()\n","\n","x_train = np.array(x_train)\n","x_test = np.array(x_test)"],"metadata":{"id":"fOm1Ao0rXawp","executionInfo":{"status":"ok","timestamp":1654744149136,"user_tz":-180,"elapsed":49152,"user":{"displayName":"Ερμης Αρβανιτης","userId":"12156976398276473890"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import re\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from pandas import concat\n","from sklearn.preprocessing import Normalizer, StandardScaler\n","from sklearn.model_selection import cross_val_score\n","import tensorflow as tf\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.callbacks import EarlyStopping\n","from keras.models import load_model\n","from sklearn import preprocessing\n","from sklearn.preprocessing import normalize, scale\n","from sklearn.model_selection import KFold\n","from tensorflow.compat.v1.losses import Reduction\n","from google.colab import files"],"metadata":{"id":"fUhsHhVwXyTB","executionInfo":{"status":"ok","timestamp":1654744156870,"user_tz":-180,"elapsed":7738,"user":{"displayName":"Ερμης Αρβανιτης","userId":"12156976398276473890"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Scaling the training and testing data\n","# Performing centering\n","x_train = x_train - x_train.mean()\n","print(x_train)\n","x_test = x_test - x_test.mean()\n","print(x_test)\n","epoch = 30\n","splits = 5\n","kfold = KFold(n_splits=splits, shuffle=True, random_state=2)\n","\n","loss = []\n","val_loss = []\n","accuracy = []\n","val_accuracy = []\n","\n","for i, (train, test) in enumerate(kfold.split(x_train)):\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.Flatten(input_shape=(counter,1)))\n","  model.add(tf.keras.layers.Dense(units=4270, activation=tf.nn.relu))\n","  model.add(tf.keras.layers.Dense(units=20, activation=tf.nn.sigmoid))\n","  model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.6), loss='mean_squared_error', metrics=['accuracy'])\n","  # model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.6), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","  history = model.fit(x_train, y_train, epochs=epoch, validation_data=(x_test, y_test), batch_size=32)\n","  los, acc = model.evaluate(x_test, y_test)\n","  loss.append(history.history['loss'])\n","  val_loss.append(history.history['val_loss'])\n","  accuracy.append(history.history['accuracy'])\n","  val_accuracy.append(history.history['val_accuracy'])\n","\n","  print(loss)\n","  print(val_loss)\n","  print(acc)\n","  print(val_accuracy)\n","\n","  \n","mean_loss = []\n","mean_val_loss = []\n","mean_accuracy = []\n","mean_val_accuracy = []\n","for i in range(epoch):\n","    temp_loss = 0\n","    temp_val_loss = 0\n","    temp_accuracy = 0\n","    temp_val_accuracy = 0\n","    for j in range(splits):\n","        temp_loss = temp_loss + loss[j][i]\n","        temp_val_loss = temp_val_loss + val_loss[j][i]\n","        temp_accuracy = temp_accuracy + accuracy[j][i]\n","        temp_val_accuracy = temp_val_accuracy + val_accuracy[j][i]\n","    mean_loss.append(temp_loss/ splits)\n","    mean_val_loss.append(temp_val_loss / splits)\n","    mean_accuracy.append(temp_accuracy / splits)\n","    mean_val_accuracy.append(temp_val_accuracy / splits)\n","\n","print(mean_loss)\n","print(mean_val_loss)\n","print(mean_accuracy)\n","print(mean_val_accuracy)\n","# Plot training and\n","epochs = range(1, len(mean_loss) + 1)\n","plt.plot(epochs, mean_loss, 'y', label='Training loss')\n","plt.plot(epochs, mean_val_loss, 'r', label='Validation loss')\n","plt.title('Training and Validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend([\"Train\", 'Validation'], loc='upper right')\n","plt.savefig('/content/drive/MyDrive/plots/loss.png')\n","plt.savefig(\"loss.png\")\n","files.download(\"loss.png\") \n","plt.show()\n","\n","\n","# Plot training and validation accuracy values\n","plt.plot(epochs, mean_accuracy, 'y', label='Training acc')\n","plt.plot(epochs, mean_val_accuracy, 'r', label='Validation acc')\n","plt.title('Training and Validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend(['Train', 'Validation'], loc='lower right')\n","plt.savefig('/content/drive/MyDrive/plots/acc.png')\n","plt.savefig(\"acc.png\")\n","files.download(\"acc.png\") \n","plt.show()\n","\n","print(los)\n","print(acc)"],"metadata":{"id":"HlT2CGipYLvR"},"execution_count":null,"outputs":[]}]}